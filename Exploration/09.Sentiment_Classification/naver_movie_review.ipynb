{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) 라이브러리 import 및 데이터 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비\n",
    "- tokenizer는 ```Mecab```을 사용\n",
    "- 불용어도 간단하게 정의 후 전처리에 사용\n",
    "- ```word_to_index```생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) index_to_word생성\n",
    "- ```word_to_index```를 활용해서 새로운 ```index_to_word```생성\n",
    "- 그외에 인덱스를 입력하면 단어로 리턴해주는 함수, 단어를 입력하면 인덱스로 리턴해주는 함수를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델구성을 위한 데이터 분석 및 가공\n",
    "- 데이터셋 내 문장 길이 분포\n",
    "- 적절한 최대 문장 길이 지정\n",
    "- keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.969376315021577\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843535456326455\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49157, 41)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) validation set 구성 및 모델선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1) validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126182, 41)\n",
      "(126182,)\n",
      "(20000, 41)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 20000건 분리\n",
    "x_val = X_train[:20000]   \n",
    "y_val = y_train[:20000]\n",
    "\n",
    "# validation set을 제외한 나머지\n",
    "partial_X_train = X_train[20000:]  \n",
    "partial_y_train = y_train[20000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2) model선정\n",
    "- 같은 파라미터로 3가지 모델을 학습\n",
    "    1. 1-D CNN\n",
    "    2. LSTM\n",
    "    3. GlobalMaxPooling1D\n",
    "- 이후에 가장 성능이 좋은 모델 선택 후 파라미터 튜닝을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세가지 모델을 평가할 때, 파라미터는 고정으로 사용\n",
    "vocab_size = len(index_to_word)\n",
    "word_vector_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 256)         537856    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 64)          114752    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,653,137\n",
      "Trainable params: 3,653,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "CNN_model = keras.Sequential(name=\"CNN\")\n",
    "CNN_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "CNN_model.add(keras.layers.Conv1D(256, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.MaxPooling1D(5))\n",
    "CNN_model.add(keras.layers.Conv1D(64, 7, activation='relu'))\n",
    "CNN_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "CNN_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "CNN_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 9888      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,009,969\n",
      "Trainable params: 3,009,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "\n",
    "LSTM_model = keras.Sequential(name=\"LSTM\")\n",
    "LSTM_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "LSTM_model.add(keras.layers.LSTM(8, dropout=0.7))\n",
    "LSTM_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GMP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 300)         3000000   \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 2408      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,002,417\n",
      "Trainable params: 3,002,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# GlobalMaxPooling1D\n",
    "\n",
    "GMP_model = keras.Sequential(name=\"GMP\")\n",
    "GMP_model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "GMP_model.add(keras.layers.GlobalMaxPooling1D())\n",
    "GMP_model.add(keras.layers.Dense(8, activation='relu'))\n",
    "GMP_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "GMP_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3가지 모델을 같은 조건에서 학습 후 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CNN', 'LSTM', 'GMP']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lst = [CNN_model.name, LSTM_model.name, GMP_model.name]\n",
    "model_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start fitting CNN ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 13s 51ms/step - loss: 0.4018 - accuracy: 0.8105 - val_loss: 0.3248 - val_accuracy: 0.8590\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.2752 - accuracy: 0.8850 - val_loss: 0.3202 - val_accuracy: 0.8630\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.1844 - accuracy: 0.9296 - val_loss: 0.3651 - val_accuracy: 0.8610\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 0.4572 - val_accuracy: 0.8534\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0566 - accuracy: 0.9811 - val_loss: 0.5419 - val_accuracy: 0.8494\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 0.6719 - val_accuracy: 0.8503\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0300 - accuracy: 0.9897 - val_loss: 0.7574 - val_accuracy: 0.8411\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0344 - accuracy: 0.9876 - val_loss: 0.7394 - val_accuracy: 0.8473\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0286 - accuracy: 0.9895 - val_loss: 0.8483 - val_accuracy: 0.8419\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0242 - accuracy: 0.9911 - val_loss: 0.8426 - val_accuracy: 0.8434\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0207 - accuracy: 0.9924 - val_loss: 0.9326 - val_accuracy: 0.8457\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 0.9833 - val_accuracy: 0.8461\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 0.9618 - val_accuracy: 0.8457\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0170 - accuracy: 0.9934 - val_loss: 1.0437 - val_accuracy: 0.8441\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0163 - accuracy: 0.9936 - val_loss: 1.0840 - val_accuracy: 0.8421\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0141 - accuracy: 0.9945 - val_loss: 1.1156 - val_accuracy: 0.8442\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 1.1074 - val_accuracy: 0.8443\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0117 - accuracy: 0.9955 - val_loss: 1.1985 - val_accuracy: 0.8456\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 1.1248 - val_accuracy: 0.8413\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 8s 33ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 1.2112 - val_accuracy: 0.8461\n",
      "Start evaluating CNN ...\n",
      "1537/1537 - 4s - loss: 1.2632 - accuracy: 0.8413\n",
      "----------------------------------------\n",
      "Start fitting LSTM ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.5879 - accuracy: 0.6904 - val_loss: 0.4847 - val_accuracy: 0.8093\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.5031 - accuracy: 0.7967 - val_loss: 0.5490 - val_accuracy: 0.7502\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.5135 - accuracy: 0.7668 - val_loss: 0.5005 - val_accuracy: 0.7792\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.4961 - accuracy: 0.7967 - val_loss: 0.4730 - val_accuracy: 0.8177\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.4781 - accuracy: 0.8119 - val_loss: 0.4768 - val_accuracy: 0.8155\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.4842 - accuracy: 0.8039 - val_loss: 0.4666 - val_accuracy: 0.8217\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.4675 - accuracy: 0.8160 - val_loss: 0.4648 - val_accuracy: 0.8192\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.4303 - accuracy: 0.8341 - val_loss: 0.4232 - val_accuracy: 0.8329\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.4376 - accuracy: 0.8249 - val_loss: 0.4495 - val_accuracy: 0.8171\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.3961 - accuracy: 0.8402 - val_loss: 0.4143 - val_accuracy: 0.8288\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.3575 - accuracy: 0.8519 - val_loss: 0.3781 - val_accuracy: 0.8421\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.3346 - accuracy: 0.8593 - val_loss: 0.3704 - val_accuracy: 0.8425\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.3163 - accuracy: 0.8646 - val_loss: 0.3600 - val_accuracy: 0.8446\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.3037 - accuracy: 0.8690 - val_loss: 0.3653 - val_accuracy: 0.8460\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.2938 - accuracy: 0.8726 - val_loss: 0.3657 - val_accuracy: 0.8367\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.2899 - accuracy: 0.8728 - val_loss: 0.3612 - val_accuracy: 0.8472\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.2898 - accuracy: 0.8751 - val_loss: 0.3752 - val_accuracy: 0.8429\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 7s 26ms/step - loss: 0.2896 - accuracy: 0.8749 - val_loss: 0.3694 - val_accuracy: 0.8477\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.2787 - accuracy: 0.8786 - val_loss: 0.3666 - val_accuracy: 0.8480\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 7s 27ms/step - loss: 0.2699 - accuracy: 0.8829 - val_loss: 0.3717 - val_accuracy: 0.8492\n",
      "Start evaluating LSTM ...\n",
      "1537/1537 - 2s - loss: 0.3823 - accuracy: 0.8424\n",
      "----------------------------------------\n",
      "Start fitting GMP ...\n",
      "Epoch 1/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.4686 - accuracy: 0.8022 - val_loss: 0.3417 - val_accuracy: 0.8487\n",
      "Epoch 2/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.3091 - accuracy: 0.8692 - val_loss: 0.3308 - val_accuracy: 0.8553\n",
      "Epoch 3/20\n",
      "247/247 [==============================] - 6s 24ms/step - loss: 0.2609 - accuracy: 0.8941 - val_loss: 0.3382 - val_accuracy: 0.8566\n",
      "Epoch 4/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.2181 - accuracy: 0.9148 - val_loss: 0.3542 - val_accuracy: 0.8557\n",
      "Epoch 5/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.1735 - accuracy: 0.9371 - val_loss: 0.3783 - val_accuracy: 0.8540\n",
      "Epoch 6/20\n",
      "247/247 [==============================] - 6s 24ms/step - loss: 0.1274 - accuracy: 0.9583 - val_loss: 0.4167 - val_accuracy: 0.8511\n",
      "Epoch 7/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0874 - accuracy: 0.9751 - val_loss: 0.4601 - val_accuracy: 0.8482\n",
      "Epoch 8/20\n",
      "247/247 [==============================] - 6s 24ms/step - loss: 0.0567 - accuracy: 0.9856 - val_loss: 0.5047 - val_accuracy: 0.8457\n",
      "Epoch 9/20\n",
      "247/247 [==============================] - 6s 24ms/step - loss: 0.0373 - accuracy: 0.9910 - val_loss: 0.5487 - val_accuracy: 0.8444\n",
      "Epoch 10/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0256 - accuracy: 0.9938 - val_loss: 0.5882 - val_accuracy: 0.8435\n",
      "Epoch 11/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.6237 - val_accuracy: 0.8413\n",
      "Epoch 12/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0147 - accuracy: 0.9957 - val_loss: 0.6522 - val_accuracy: 0.8436\n",
      "Epoch 13/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.6796 - val_accuracy: 0.8431\n",
      "Epoch 14/20\n",
      "247/247 [==============================] - 6s 24ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.7061 - val_accuracy: 0.8429\n",
      "Epoch 15/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.7284 - val_accuracy: 0.8428\n",
      "Epoch 16/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.7502 - val_accuracy: 0.8435\n",
      "Epoch 17/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0078 - accuracy: 0.9966 - val_loss: 0.7748 - val_accuracy: 0.8418\n",
      "Epoch 18/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0070 - accuracy: 0.9968 - val_loss: 0.7887 - val_accuracy: 0.8431\n",
      "Epoch 19/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 0.8036 - val_accuracy: 0.8426\n",
      "Epoch 20/20\n",
      "247/247 [==============================] - 6s 25ms/step - loss: 0.0065 - accuracy: 0.9968 - val_loss: 0.8236 - val_accuracy: 0.8429\n",
      "Start evaluating GMP ...\n",
      "1537/1537 - 1s - loss: 0.8397 - accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "model_result = {}\n",
    "\n",
    "for model_name in model_lst:\n",
    "    \n",
    "    if model_name == \"CNN\":\n",
    "        model = CNN_model\n",
    "    elif model_name == \"LSTM\":\n",
    "        model = LSTM_model\n",
    "    else :\n",
    "        model = GMP_model\n",
    "    \n",
    "    print('-'*40)\n",
    "    print(\"Start fitting {} ...\".format(model_name))\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs=20\n",
    "\n",
    "    history = model.fit(partial_X_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=epochs,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1)\n",
    "    \n",
    "    \n",
    "    print(\"Start evaluating {} ...\".format(model_name))\n",
    "    results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "    model_result[model_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM \t 0.842443585395813\n",
      "CNN \t 0.8413450717926025\n",
      "GMP \t 0.8402465581893921\n"
     ]
    }
   ],
   "source": [
    "for name, [_, acc] in sorted(model_result.items(), key=lambda x : x[1][1], reverse=True) :\n",
    "    print(name,'\\t',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 모델 훈련\n",
    "- 위의 모델 중에서 LSTM의 성능이 가장 좋았다.\n",
    "- 모델을 훈련하기 전에 먼저 성능을 올릴 수 있는 최적의 하이퍼파라미터를 찾아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적의 모델 만들기\n",
    "- LSTM모델 앞에 CNN을 추가도 해보았고, LSTM을 추가도 해보았다.\n",
    "    - CNN의 경우는 추가를 하면 성능이 더 나빴다.\n",
    "    - LSTM층을 하나 더 추가할 경우 결과는 크게 달라지지 않았지만 학습 곡선이 다르게 나타나는 것을 알 수 있었다.\n",
    "- 간단하게 LSTM 레이어 하나만을 사용해서 하이퍼파라미터를 튜닝해보도록 하였다.\n",
    "    - ```word_vector_dim``` 을 늘려가면서 성능이 점점 더 좋아지는 것을 알 수 있었다.\n",
    "        - 1000\n",
    "    - ```LSTM``` 레이어의 벡터 차원수를 기존에 8에서 128까지 늘렸다.\n",
    "        - input dimension이 1000개에 반해 128개의 차원은 여전히 부족하지 않을까?\n",
    "    - ```Overfitting```이 자주 발생하여서 ```LSTM```의 인자로 ```Dropout```도 추가하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vector_dim = 1000  # 워드 벡터의 차원수\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "# CNN을 추가했을 때\n",
    "# model.add(keras.layers.Conv1D(8, 7, activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling1D())\n",
    "# LSTM 레이어를 두개로 학습했을 때\n",
    "# model.add(keras.layers.LSTM(256, dropout=0.7, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(128, dropout=0.7))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 이진분류\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 20번 epoch을 돌리는 동안 ```validation loss```값이 오르는 것을 확인할 수 있었다.(**Overfitting 발생**)  \n",
    "\n",
    "그렇게 때문에 ```callback```의 ```EarlyStopping```을 사용하였고 최적의 모델을 저장하기 위해서 ```ModelCheckpoint```를 사용하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```optimizer```에서 사용하는 ```Adam```에도 ```learning rate```를 조절해주었다.  \n",
    "이전에 세가지 모델을 학습시켜보았을 때 여러번 학습이 진행되기 전에 **Overfitting**이 발생하였기 때문에 학습률을 낮추었다.\n",
    "추가적으로 배치사이즈도 더 작게 설정하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.7802\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84590, saving model to model.h5\n",
      "986/986 [==============================] - 72s 73ms/step - loss: 0.4350 - accuracy: 0.7802 - val_loss: 0.3492 - val_accuracy: 0.8459\n",
      "Epoch 2/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.3221 - accuracy: 0.8618\n",
      "Epoch 00002: val_accuracy improved from 0.84590 to 0.85915, saving model to model.h5\n",
      "986/986 [==============================] - 71s 72ms/step - loss: 0.3221 - accuracy: 0.8618 - val_loss: 0.3339 - val_accuracy: 0.8591\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2865 - accuracy: 0.8783\n",
      "Epoch 00003: val_accuracy improved from 0.85915 to 0.86455, saving model to model.h5\n",
      "986/986 [==============================] - 71s 72ms/step - loss: 0.2865 - accuracy: 0.8783 - val_loss: 0.3230 - val_accuracy: 0.8645\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.8894\n",
      "Epoch 00004: val_accuracy improved from 0.86455 to 0.86605, saving model to model.h5\n",
      "986/986 [==============================] - 71s 72ms/step - loss: 0.2630 - accuracy: 0.8894 - val_loss: 0.3212 - val_accuracy: 0.8661\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.8983\n",
      "Epoch 00005: val_accuracy did not improve from 0.86605\n",
      "986/986 [==============================] - 71s 72ms/step - loss: 0.2424 - accuracy: 0.8983 - val_loss: 0.3243 - val_accuracy: 0.8629\n",
      "Epoch 6/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.9063\n",
      "Epoch 00006: val_accuracy did not improve from 0.86605\n",
      "986/986 [==============================] - 71s 72ms/step - loss: 0.2247 - accuracy: 0.9063 - val_loss: 0.3605 - val_accuracy: 0.8660\n",
      "Epoch 7/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.9142\n",
      "Epoch 00007: val_accuracy did not improve from 0.86605\n",
      "986/986 [==============================] - 71s 72ms/step - loss: 0.2086 - accuracy: 0.9142 - val_loss: 0.3685 - val_accuracy: 0.8647\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.3759 - accuracy: 0.8600\n",
      "[0.3759104311466217, 0.8600403070449829]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 학습시킨 결과 ```0.842```에서 ```0.86```까지 정확도가 상승하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Loss, Accuracy 그래프 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5yM5fvA8c9lnS3KMWdLIqfdZamQnCqVn1Qkia9UDqUDCZUi0verfFNKB4mOkupLlEpkQ2fHiqholUiF2M2Z6/fHPWvHtsvs7Mw+s+N6v17z2jk8zzPXvctc89z3c1+3qCrGGGNMZgW8DsAYY0xksgRhjDEmS5YgjDHGZMkShDHGmCxZgjDGGJMlSxDGGGOyZAnC5AkReU9E/hXqbb0kIiki0iEMx1UROdN3/xkRuS+QbYN4n54isiDYOE9w3DYisiXUxzV5r6DXAZjIJSJpfg+LAweAI77H/VX11UCPpaqXhGPbaKeqA0JxHBGpCfwEFFLVw75jvwoE/Dc0px5LECZbqhqbfl9EUoAbVXVh5u1EpGD6h44xJnpYF5PJsfQuBBEZLiK/AdNF5HQReUdE/hCRXb77Vf32SRaRG333+4jIMhGZ4Nv2JxG5JMht40RkiYikishCEZksIq9kE3cgMY4VkU98x1sgIuX8Xu8lIptFZIeI3HuC38+5IvKbiMT4PXeFiHztu99cRD4Tkb9EZJuIPCkihbM51gsi8qDf47t8+2wVkb6Ztr1MRFaJyB4R+UVERvu9vMT38y8RSROR89J/t377txCRr0Rkt+9ni0B/NyciImf79v9LRNaKSGe/1y4VkXW+Y/4qIkN9z5fz/X3+EpGdIrJUROzzKo/ZL9wE6wygDFAD6If7tzTd97g6sA948gT7nwNsAMoBDwPPi4gEse0M4EugLDAa6HWC9wwkxmuB64EKQGEg/QOrPvC07/iVfe9XlSyo6ufA30C7TMed4bt/BBjsa895QHvg5hPEjS+Gjr54LgTqAJnHP/4GegOnAZcBA0Wki++11r6fp6lqrKp+lunYZYB3gUm+tj0KvCsiZTO14R+/m5PEXAiYByzw7Xcr8KqI1PVt8jyuu7Ik0BD4yPf8ncAWoDxQEbgHsLpAecwShAnWUWCUqh5Q1X2qukNV31LVvaqaCowDLjjB/ptV9TlVPQK8CFTCfRAEvK2IVAeaAfer6kFVXQbMze4NA4xxuqp+r6r7gFlAgu/5rsA7qrpEVQ8A9/l+B9l5DegBICIlgUt9z6GqK1T1c1U9rKopwLNZxJGVq33xfauqf+MSon/7klX1G1U9qqpf+94vkOOCSyg/qOrLvrheA9YD/+e3TXa/mxM5F4gF/uP7G30EvIPvdwMcAuqLSClV3aWqK/2erwTUUNVDqrpUrXBcnrMEYYL1h6ruT38gIsVF5FlfF8weXJfGaf7dLJn8ln5HVff67sbmcNvKwE6/5wB+yS7gAGP8ze/+Xr+YKvsf2/cBvSO798KdLVwpIkWAK4GVqrrZF8dZvu6T33xxPIQ7mziZ42IANmdq3zkistjXhbYbGBDgcdOPvTnTc5uBKn6Ps/vdnDRmVfVPpv7HvQqXPDeLyMcicp7v+UeAH4EFIrJJREYE1gwTSpYgTLAyf5u7E6gLnKOqpcjo0siu2ygUtgFlRKS433PVTrB9bmLc5n9s33uWzW5jVV2H+yC8hOO7l8B1Va0H6vjiuCeYGHDdZP5m4M6gqqlqaeAZv+Oe7Nv3VlzXm7/qwK8BxHWy41bLNH5w7Liq+pWqXo7rfpqDOzNBVVNV9U5VrYU7ixkiIu1zGYvJIUsQJlRK4vr0//L1Z48K9xv6vpEvB0aLSGHft8//O8EuuYnxTaCTiLTyDSiP4eT/f2YAt+ES0RuZ4tgDpIlIPWBggDHMAvqISH1fgsocf0ncGdV+EWmOS0zp/sB1idXK5tjzgbNE5FoRKSgi3YH6uO6g3PgCNzYyTEQKiUgb3N9opu9v1lNESqvqIdzv5AiAiHQSkTN9Y03pzx/J+i1MuFiCMKHyGFAM+BP4HHg/j963J26gdwfwIPA6br5GVoKOUVXXArfgPvS3Abtwg6gn8hrQBvhIVf/0e34o7sM7FXjOF3MgMbzna8NHuO6XjzJtcjMwRkRSgfvxfRv37bsXN+byie/KoHMzHXsH0Al3lrUDGAZ0yhR3jqnqQaAz7kzqT+ApoLeqrvdt0gtI8XW1DQCu8z1fB1gIpAGfAU+panJuYjE5JzbuY6KJiLwOrFfVsJ/BGBPt7AzC5Gsi0kxEaotIAd9loJfj+rKNMblkM6lNfncG8D/cgPEWYKCqrvI2JGOig3UxGWOMyZJ1MRljjMlSVHUxlStXTmvWrBnUvn///TclSpQIbUAeiZa2REs7wNoSiaKlHZC7tqxYseJPVS2f1WtRlSBq1qzJ8uXLg9o3OTmZNm3ahDYgj0RLW6KlHWBtiUTR0g7IXVtEJPMM+mOsi8kYY0yWLEEYY4zJkiUIY4wxWYqqMQhjTN46dOgQW7ZsYf/+/SffOMKULl2a7777zuswQiKQthQtWpSqVatSqFChgI9rCcIYE7QtW7ZQsmRJatasSfbrPUWm1NRUSpYs6XUYIXGytqgqO3bsYMuWLcTFxQV8XOtiMsYEbf/+/ZQtWzbfJYdTjYhQtmzZHJ/pWYIwxuSKJYf8IZi/kyWI/fthwgRKf/2115EYY0xEsQQB8Nhj1HruObC6VMbkKzt27CAhIYGEhATOOOMMqlSpcuzxwYMHT7jvypUrue222076Hi1atAhJrMnJyXTq1Ckkx8orNkhdtCiMHEnpgQPhgw+gY0evIzLGBKhs2bKsXr0agNGjRxMbG8vQoUOPvX748GEKFsz6Y65JkyZccMEFJ32PTz/9NDTB5kN2BgHQty/7zjgDRo60swhj8rk+ffowZMgQ2rZty/Dhw/nyyy9p0aIFiYmJtGjRgg0bNgCwdOnSY9/oR48eTd++fWnTpg21atVi0qRJx44XGxsLZJSz6Nq1K/Xq1aNnz56kV8OeP38+9erVo1WrVtx2220nPVPYuXMnXbp0oXHjxpx77rl87evi/vjjj4+dASUmJpKamsq2bdto3bo1CQkJNGzYkKVLl4b8d5YdO4MAKFyYzb17U+/hh+Htt6FLF68jMib/ueMO8H2bD5mEBHjssRzv9v3337Nw4UJiYmLYs2cPS5YsoWDBgixcuJB77rmHt9566x/7rF+/nsWLF5OamkrdunUZOHDgP+YMrFq1irVr11K5cmVatmzJJ598QlJSEv3792fJkiXExcXRo0ePk8Y3atQoEhMTmTNnDh999BG9e/dm9erVTJgwgcmTJ9OyZUvS0tIoWrQoU6ZM4eKLL+bee+/lyJEj7N27N8e/j2DZGYTP9osugjp14P774ehRr8MxxuRCt27diImJAWD37t1069aNhg0bMnjwYNauXZvlPpdddhlFihShXLlyVKhQge3bt/9jm+bNm1O1alUKFChAQkICKSkprF+/nlq1ah2bXxBIgli2bBm9evUCoF27duzYsYPdu3fTsmVLhgwZwqRJk/jrr78oWLAgzZo1Y/r06YwePZpvvvkmT+du2BmEj8bEwAMPwLXXwhtvQPfuXodkTP4SxDf9cPEvfX3ffffRtm1bZs+eTUpKSrZVT4sUKXLsfkxMDIcPHw5om2AWXctqHxFhxIgRXHbZZcyfP59zzz2XhQsX0rp1a5YsWcK7775Lr169uOuuu+jdu3eO3zMYdgbhr3t3aNAARo2CLP5xGGPyn927d1OlShUAXnjhhZAfv169emzatImUlBQAXn/99ZPu07p1a1599VXAjW2UK1eOUqVKsXHjRho1asTw4cNJSkpi/fr1bN68mQoVKnDTTTdxww03sHLlypC3ITuWIPwVKABjxsCGDTBjhtfRGGNCYNiwYdx99920bNmSI0eOhPz4xYoV46mnnqJjx460atWKihUrUrp06RPuM3r0aJYvX07jxo0ZMWIEL774IgCPPfYYDRs2JD4+nmLFinHJJZeQnJx8bND6rbfe4vbbbw95G7KlqlFza9q0qQZr8eLF7s7Ro6qJiapxcaoHDwZ9PC8da0s+Fy3tUI3etqxbt867QHJpz549ITtWamqqqqoePXpUBw4cqI8++mjIjh2IQNuS1d8LWK7ZfKbaGURmIvDgg/DTTzB9utfRGGPygeeee46EhAQaNGjA7t276d+/v9chhYQNUmflkkvg3HNh7Fjo3dtNpjPGmGwMHjyYwYMHex1GyNkZRFbSzyK2bIHnnvM6GmOM8YQliOy0awdt2sC4cZCHE1OMMSZSWILIjojrYtq+HSZP9joaY4zJc5YgTqRVK7j4Yhg/HlJTvY7GGGPylCWIkxk7FnbsgMcf9zoSY0wmbdq04YMPPjjuuccee4ybb775hPssX74cgEsvvZS//vrrH9uMHj2aCRMmnPC958yZw7p16449vv/++1m4cGFOws9SJJUFtwRxMs2aweWXw4QJsGuX19EYY/z06NGDmTNnHvfczJkzA6qHBK4K62mnnRbUe2dOEGPGjKFDhw5BHStSWYIIxJgxsHs3/Pe/XkdijPHTtWtX3nnnHQ4cOABASkoKW7dupVWrVgwcOJCkpCQaNGjAqFGjsty/Zs2a/PnnnwCMGzeOunXr0qFDh2MlwcHNcWjWrBnx8fFcddVV7N27l08//ZS5c+dy1113kZCQwMaNG+nTpw9vvvkmAIsWLSIxMZFGjRrRt2/fY/HVrFmTUaNG0aRJExo1asT69etP2D6vy4LbPIhANG4MV1/tupluvx3Kl/c6ImMijhfVvsuWLUvz5s15//33ufzyy5k5cybdu3dHRBg3bhxlypThyJEjtG/fnq+//prGjRtneZwVK1Ywc+ZMVq1axeHDh2nSpAlNmzYF4Morr+Smm24CYOTIkTz//PPceuutdO7cmU6dOtG1a9fjjrV//3769OnDokWLOOuss+jduzdPP/00d9xxBwDlypVj5cqVPPXUU0yYMIGpU6dm275Ay4IfOnSIadOmhbwsuJ1BBGr0aHe568MPex2JMcaPfzeTf/fSrFmzaNKkCYmJiaxdu/a47qDMli5dyhVXXEHx4sUpVaoUnTt3Pvbat99+y/nnn0+jRo149dVXsy0Xnm7Dhg3ExcVx1llnAfCvf/2LJUuWHHv9yiuvBKBp06bHCvxlx+uy4HYGEaizz4brroMnn4QhQ6BSJa8jMiaieFXtu0uXLgwZMoSVK1eyb98+mjRpwk8//cSECRP46quvOP300+nTpw/79+8/4XFEJMvn+/Tpw5w5c4iPj+eFF14gOTn5hMfRk5T/Ti8Znl1J8ZMdK6uy4G+//XZYyoLbGURO3H8/HDoE//6315EYY3xiY2Np06YNffv2PXb2sGfPHkqUKEHp0qXZvn0777333gmP0bp1a2bPns2+fftITU1l3rx5x15LTU2lUqVKHDp06FiJboCSJUuSmsXl7/Xq1SMlJYUff/wRgJdffjmgta+ziyuQsuDff/99WMqC2xlETtSuDX37wrPPwtChUL261xEZY3DdTFdeeeWxrqb4+HgSExNp0KABtWrVomXLlifcv0mTJnTv3p2EhARq1KjB+eeff+y1sWPHcs4551CjRg0aNWp0LClcc8013HTTTUyaNOnY4DRA0aJFmT59Ot26dePw4cM0a9aMAQMGBNWu0aNHc/3119O4cWOKFy9+XFnwxYsXExMTQ/369bnwwgt59913eeSRRyhUqBCxsbG89NJLQb3ncbIr85ofbyEp930ymzerFi6setNNQb9XuEVLaeloaYdq9LbFyn1HBiv3HSmqV4d+/WDaNNi40etojDEmbCxBBOOee6BQITc/whhjopQliGBUqgSDBsErr8B333kdjTGe0pNctWMiQzB/J0sQwRo2DIoXd/MjjDlFFS1alB07dliSiHCqyo4dOyiaw8XPwnoVk4h0BB4HYoCpqvqfbLZrBnwOdFfVN3Oyr2fKl3ezqseNc11O8fFeR2RMnqtatSpbtmzhjz/+8DqUHNu/f3+OPzAjVSBtKVq0KFWrVs3RccOWIEQkBpgMXAhsAb4Skbmqui6L7cYDH+R0X8/deaebODdqFMyZ43U0xuS5QoUKERcX53UYQUlOTiYxMdHrMEIiXG0JZxdTc+BHVd2kqgeBmcDlWWx3K/AW8HsQ+3rr9NPdfIi334avvvI6GmOMCalwdjFVAX7xe7wFOMd/AxGpAlwBtAOa5WRfv2P0A/oBVKxY8aTT4LOTlpYW1L4xTZpwbqlSpN5yC19HSJ2mYNsSaaKlHWBtiUTR0g4IX1vCmSCyKmySeSTrMWC4qh7JVAclkH3dk6pTgCkASUlJ2qZNm5xHijtFC3ZfRo6kzLBhtClY0K1C57FctSWCREs7wNoSiaKlHRC+toSzi2kLUM3vcVVga6ZtkoCZIpICdAWeEpEuAe4bOW65BSpWhJEjwa7mMMZEiXAmiK+AOiISJyKFgWuAuf4bqGqcqtZU1ZrAm8DNqjonkH0jSvHicO+98PHH8NFHXkdjjDEhEbYEoaqHgUG4q5O+A2ap6loRGSAiJ6xcld2+4Yo1JPr1g2rV7CzCGBM1wjoPQlXnA/MzPfdMNtv2Odm+Ea1IEZcc+veH996DSy/1OiJjjMkVm0kdStdfD7Vq2VmEMSYqWIIIpUKF3KS5Vatg9myvozHGmFyxBBFqPXtC3bpu9bkjR7yOxhhjgmYJItRiYuCBB2DtWpg1y+tojDEmaJYgwqFbN2jUyHU3nWRRcmOMiVSWIMKhQAEYOxZ++AFeftnraIwxJiiWIMKlc2dISnKrzh086HU0xhiTY5YgwkXEnUWkpLj1q40xJp+xBBFOF18MLVvCgw/C/v1eR2OMMTliCSKcRFxy+PVXePZZr6MxxpgcsQQRbm3aQLt28NBD8PffXkdjjDEBswSRF8aOhd9/d8uTGmNMPmEJIi+0aOGK9z38MOzZ43U0xhgTEEsQeWXMGNi5Ex57zOtIjDEmIJYg8krTpnDFFfDf/7pEYYwxEc4SRF564AFITYUJE7yOxBhjTsoSRF5q1AiuuQYmTXKD1sYYE8EsQeS1UaNg3z4YP97rSIwx5oQsQeS1unWhd2946ik3gc4YYyKUJQgv3H+/KwP+0ENeR2KMMdmyBOGFuDi48UZ47jnYvNnraIwx+YyqG8b87DN45RWYO7dSWN6nYFiOak7u3nth+nQ3y3rqVK+jMcZEmCNH4JdfYONGd/vxx4z7GzdCWlrGtiVL1uLRR0MfgyUIr1StCgMGuPIbw4dDnTpeR2SMyWP79sFPP2WdBFJS4NChjG0LF4ZataB2bbjgAvcz/fbzz58CF4Q8PksQXhoxwnUzPfCAO080xkSdXbuO/+bvnwgyX6dSurT7wE9IgKuuOj4JVKnilrzPym+/aVhitwThpTPOgEGD4JFH4J57oH59ryMyxuTQ0aOwbVv2SWDXruO3r1TJfeB36HB8AqhdG8qWdasERApLEF4bNgyeftrNj3jjDa+jMcZk4dAh1+WTVRLYtOn49cBiYqBmTfeB36zZ8QmgVi0oUcKrVuScJQivlS0Lgwe7Yn6rV7tzS2NMnktL+2cCSL9t3uzOFNIVL+4+8M86Cy655PgkUL06FCrkXTtCyRJEJBg8GJ54ws2PmDvX62iMiXrbtsHLL9dg2rSMJLB9+/HblCvnPvDPOw+uu+74JHDGGZHVFRQuliAiwWmnwdCh7tLXL76Ac87xOiJjotLRo2713xEjIDW1JlWrwplnwv/93z/HA0qX9jpa71mCiBS33QYTJ8J998GCBV5HY0zUWbMG+vd338Hat4c+fb7kuuvsy9iJ2EzqSBEbC3ffDR9+CEuWeB2NMVHj77/hrrvckiybNrkryj/8EKpW3ed1aBHPEkQkGTjQXQM3cqSbS2+MyZV33nFXj0+YAH37wvr10LPnqTF+EAqWICJJsWJuHGLpUli40OtojMm3fv0VunZ1Ywuxse6/1JQpUKaM15HlL5YgIs2NN7rr5OwswpgcO3LEXRB49tnw7ruuYPKqVdCqldeR5U9hTRAi0lFENojIjyIyIovXLxeRr0VktYgsF5FWfq+liMg36a+FM86IUqSIu9z1yy/dv3BjTEBWrYJzz3XXe5x3Hnz7rRvWK1zY68jyr7AlCBGJASYDlwD1gR4ikrmWxCIgXlUTgL5A5rKmbVU1QVWTwhVnROrd211nd999x8/OMcb8Q1oaDBkCSUmu+ulrr8H777v/QiZ3wnkG0Rz4UVU3qepBYCZwuf8GqpqmeqwfpQRgfSrgpmGOHu1mVv/vf15HY0zEevttNwg9cSL06+cGoa+5xgahQ0U0TP3cItIV6KiqN/oe9wLOUdVBmba7Avg3UAG4TFU/8z3/E7ALlzSeVdUp2bxPP6AfQMWKFZvOnDkzx7E++eSZlC37F+edt5caNfZGxj+uI0dodsMNAHz1/PPZl3HMQlpaGrGxseGKLM9ESzvA2hJqv/9ehCeeOJNly8pTq1YaQ4Z8T4MGe3J0jEhoR6jkpi1t27ZdkW0vjaqG5QZ0A6b6Pe4FPHGC7VsDC/0eV/b9rACsAVqf7D2bNm2qObVvn2rt2qpuRFi1UiXVnj1Vp09X/fnnHB8utN54wwX1yis52m3x4sXhiSePRUs7VK0toXLokOrEiaqxsarFiqmOH6968GBwx7K/iQMs12w+U8PZxbQFqOb3uCqwNbuNVXUJUFtEyvkeb/X9/B2YjeuyCrmiRV1FxhkzPue559xCHAsWwPXXu4uJzjrLTU946y3YuTMcEZzAlVdCfLzrbvJfOcSYU9Dy5a4KzeDBcP75sHatK4YcLYXxIlE4E8RXQB0RiRORwsA1wHGV6ETkTBHXoSMiTYDCwA4RKSEiJX3PlwAuAr4NY6xUqrSfG290A1y//eam5T/6qEsQr7zirqkuV87Nxhw2zCWRvXvDGRFQoIBbkvTHH+Gll8L8ZsZEpj174PbbXXLYuhVmzXIX+MXFeR1Z9AtbLSZVPSwig4APgBhgmqquFZEBvtefAa4CeovIIWAf0F1VVUQqArN9uaMgMENV3w9XrJkVKACNG7vb4MHuy/uXX8KiRe722GNujZ/Chd3ldO3bu1uzZmH4NtOpEzRv7sqBX3eduwzWmFOAKsyeDbfe6qqv3nwzjBtnRfTyUliL9anqfGB+puee8bs/HhifxX6bgPhwxpYThQpBy5budv/9rrbL0qUZCWPUKPd8yZKuiyo9YTRsGIKrKUTgwQfhoovg+efd/xJjotzmzS4xzJvnellnz3bfk0zesmquQShRAjp2dDeAHTtg8WJXHWPRIlf/BaBChYxk0b69W2UqKB06uE7XBx90gyPFioWiGcZEnMOH4fHH3RcucDWUbr8dCtonlSes1EYIlC3rxiieeQZ++MF9+5k2zX2uf/SRq54RF+cm7vTv7/pQ//gjB2+QfhaxbZtbntSYKPTFF26y29Ch7gvVunVw552WHLxkCSIMqld3X/RffdV9pn/7rftW1LAhzJwJ3bu7s4uEBPcf4L333GzQE2rdGi68EP7znwA2Nib/2L0bBg1y43l//unmhr79NtSo4XVkxhJEmIlAgwauPszbb7vuqM8+cycEZcrAk0/CpZfC6ae7XqTRo2HZMjh4MIuDjR3rTj2eeCKvm2FMyKnCG2+4wnpPP+3GHNatgyuusJnQkcISRB4rWNAVFLv3Xtf9tGuXu2T2zjth/353sdL557vkceml8N//uoobR4/irvPr1Akefhj++svrphgTtJQU90/56qvdEihffOHOskuV8joy48969zxWvLjrObrwQvd4505ITs64Quq999zz5cpBu3bQPn4y7d9pS61HJyJjHvAsbmOCceiQq5s0erSrHjNxoutesnGGyGR/lghTpoybQH3lle7xli3uTCP9CqlZs6oDG6nx4GY6bNpP+8uK0q4dVKzoadjGnNRnn7mLNL75Brp0gUmToFq1k+9nvGMJIsJVreqqf/fu7fpsN2yARa9sY9G4Fbz15iU8/6rbrmFDd9VUu3Zw6JAVwDeRY9cuty7DlClQpQrMmQOXX37y/Yz3LEHkIyJQrx7Ue7ASt6T8jyP/+xcr30th0eqyLFrkLrN97DGAFlSs6K6S8r/VqZOjorDG5IoqvP463HGHu7bijjvggQfchFKTP1iCyK9GjSJm5kyaffAgzSZOZMQIN8j95Zcwa9YP/P13HVavdvWk0uv8FSvmyockJEBiovvZqJEbBzEmlDZudJP+Fyxwcxvmz4cmTbyOyuSUJYj8qk4d6NPHXR94551QtSpFi7rpEkeP/kqbNnUAd7nsd9+5K6HSb6+/Ds8+6w5ToIArSJj5bMPGNEwwDh50s5/HjnUlaiZNconCzlzzp4AShK+i6j5VPSoiZwH1gPdU1WpQe+m++1yV13Hjsp1hXbiwq2UTHw//+pd7ThV+/jkjYaxa5QYQ/ddaOuOM4xNGYqKbCW7/0U12li1zg9Dr1sFVV7nLVqtU8ToqkxuBnkEsAc4XkdNx60gvB7oDPcMVmAlAjRpw001u9G/YsIDrH4u4XWvUOH6wcNcuV+bc/2xj4UJXHwdcDar0Lqr0W8OG1kV1qtu5E4YPh6lTXRWBefPcHAeT/wWaIERV94rIDbhV4R4WkVXhDMwE6N57XeGnsWPdz1w4/XRo08bd0h048M8uqhkzMk5YChSAunX/2UVVoUKuQjH5gKorJzNkiEsSQ4e6+Q0lSngdmQmVgBOEiJyHO2O4IYf7mnCqXNkteff44zBihBtQCKEiRTI+9NOpupmw/knjk0/cYkv+YWVOGrVru4Ri8r8ffnD/7BYtchP8P/zQdWOa6BLoh/wdwN3AbN+iP7WAxeELy+TIiBFu1Hn0aPf1PsxEXG9WXJyrm5Nu585/dlEtWHB8F1V8/D+7qKx6ef5x4AC89FINZsxwXx6eegr69bOxqWgVUIJQ1Y+BjwFEpADwp6reFs7ATA5UqOCK5v/nP3DPPZ6FUaYMtG3rbukOHHCDlv4D4i+/7D5YwJ1R1Kt3/KW38fFQvrw3bTgVHDjglvE82S019Z/P/fIL/PZbHKUY2iEAABkySURBVFdf7ebcVKrkdWtMOAV6FdMMYABwBFgBlBaRR1X1kXAGZ3Jg6FCYPNktb3frrV5Hc0yRIu6DPzEx47mjR//ZRbV06fEnP1WqQIUK8VSpAkWLurOMokUzbv6PT/RadtsWLJi/KoYePepWMgzmQz3z7VAA1x7GxLjCeaVKuYltpUq5dU9q14aEhK8ZPrxx+BttPBdoF1N9Vd0jIj1xS4gOxyUKSxCRokwZN1o4ejTVypd366OGfIHs0ChQAGrVcrf0mlPgSqH7d1GtXFmArVvdBMB9+9xP//u5jSE3iSenSWnbtqKsWZPzD/P0W1qaG/s5mWLF/vnBXqNGxnOZb+nbZL4VK5Z9Ak1O3pm7X77JNwJNEIVEpBDQBXhSVQ+JSAD/XE2euvNOWL6c2s8+C59+6i41atnS66gCVrasqyXVrp17nJy8ijb+l1T5UXWTsrJLHoE8PtFre/e6hJXdtjl3braviPzzQ7t0aVfILicf7CVLRux3ApNPBZogngVSgDXAEhGpAewJV1AmSLGxMHcu344bR8MpU6BVK+jbF8aPd/XCo4iI674qUsR9mOYlVdePn5PE88MP33HOOWdn+cFeokT+6u4yp45AB6knAZP8ntosIm2z2954SIQ/W7VyldHGjHEF9+fMcUmib1+7zjQERDK6jwKVnLydNm3ODl9QxoRBQJ8WIlJaRB4VkeW+238Bmw4TyWJj3cpzq1a5NU9vusmdUaxZ43Vkxph8ItCvk9OAVOBq320PMD1cQZkQatgQPv4YXnjBzW5q2tQNZqemeh2ZMSbCBZogaqvqKFXd5Ls9ANQKZ2AmhERcpb4NG+CGG1y309lnw5tvBnZpjDHmlBRogtgnIq3SH4hIS2BfeEIyYVOmjJtx/dlnbtC6Wze49FJXvN8YYzIJNEEMACaLSIqIpABPAv3DFpUJr3PPheXL3VTYTz5xYxRjxuR+coExJqoElCBUdY2qxgONgcaqmgi0C2tkJrwKFnTlOdavdyvIjxrlanl/+KHXkRljIkSOrnlU1T2qmj7/YUgY4jF5rXJlt1LQBx+48YiLLoJrroGtW72OzBjjsdxcFG9Te6LJRRfBN9+4irBz5rgKeo8/nlGK1RhzyslNgrDLX6JN0aKuq+nbb6FFCzfZrnlz+OILryMzxnjghAlCRFJFZE8Wt1Sgch7FaPLamWfCe+/BrFmwfTucdx4MGOAWfDDGnDJOmCBUtaSqlsriVlJVbUW5aCbiLoNdv96dSUyd6rqdXnzR5k4Yc4qwwjzmxEqWhEcfhRUr3JlFnz5wwQWwdq3XkRljwswShAlMfDwsWwbPPeeSQ0ICDB/uVrExxkSlsCYIEekoIhtE5EcRGZHF65eLyNcistpXBLBVoPsaDxQoADfe6Lqdevd2xQDr13dXPVm3kzFRJ2wJQkRigMnAJUB9oIeI1M+02SIgXlUTgL7A1Bzsa7xSvjw8/7xbJ7RUKbjiCujc2a0jaoyJGuE8g2gO/Ogr7ncQmAlc7r+BqqapHvvqWYKMS2dPuq+JAK1awcqV8MgjsHixO5t46CG31JsxJt8TDVPXgIh0BTqq6o2+x72Ac1R1UKbtrgD+DVQALlPVzwLd1/daP6AfQMWKFZvOnDkzqHjT0tKIjY0Nat9I40Vbivz+O2c++STlly7l7+rV+eGOO/grMTFXx7S/SWSKlrZESzsgd21p27btClVNyvJFVQ3LDegGTPV73At44gTbtwYWBrNv+q1p06YarMWLFwe9b6TxtC3vvqsaF6cKqtddp/rbb0Efyv4mkSla2hIt7VDNXVuA5ZrNZ2o4u5i2ANX8HlcFsi3wo6pLgNoiUi6n+5oIcumlbib2yJHw+utQty489RQcOeJ1ZMaYHApngvgKqCMicSJSGLgGmOu/gYicKeKWaxeRJkBhYEcg+5oIVrw4jB3rajs1bQq33JJRYtwYk2+ELUGo6mFgEPAB8B0wS1XXisgAERng2+wq4FsRWY27aqm776wny33DFasJk7p1YeFCmDEDtmxxdZ0GDYK//vI6MmNMAMJaLkNV5wPzMz33jN/98cD4QPc1+ZAI9Ojhup5GjnTdTW++6WZn9+jhXjfGRCSbSW3yRunS8MQT8OWXUK0a9OwJHTq4SXfGmIhkCcLkraZN4fPP3ZnEihVuFbuRI2HvXq8jM8ZkYgnC5L2YGBg4EDZscKvXjRvn1sV+912vIzPG+LEEYbxTsSK89JKbhV2sGHTqBFdeCb/84nVkxhgsQZhI0KYNrF7tynS8/z6cfTY88ghiy50a4ylLECYyFC4Md98N69ZBu3YwbBjN+vaFJ5+E3bu9js6YU5IlCBNZataEuXPh7bc5XLw43HorVK7syox/9ZWVFTcmD1mCMJGpc2dWPvOMSwrXXguvveYm2iUlwZQpkJbmdYTGRD1LECayJSW5Vey2boXJk+HQIejf351V3HwzrFnjdYTGRC1LECZ/KF06IyF8+qlbpGjaNLf06XnnwYsvwr59XkdpTFSxBGHyF5GMhLB1K0ycCLt2QZ8+7qzijjvgu++8jtKYqGAJwuRfZcpkJITkZOjY0c3Qrl8fLrjAjVscOOB1lMbkW5YgTP4nkpEQtmyB8ePdz2uvhapVYdgw+PFHr6M0Jt+xBGGiS4UKLiH88AN88AG0bu0qx9apAxdeCG+95Qa6jTEnZQnCRKcCBeCii1xC+Plnt4DRhg3QtStUr+4KBG7e7HWUxkQ0SxAm+lWu7BLCTz/BvHmuouxDD0FcnKv/NG+eLYlqTBYsQZhTR0yMSwjvvOOSxb33wsqV0LmzSxZjx7oro4wxgCUIc6qqUcMlhM2bXTdUvXpw//2u++nKK934xdGjXkdpjKcsQZhTW6FCLiEsWOAGtu+8E5YudZfM1qnjroj6/XevozTGE5YgjEl35pkZl8i+9ppbGnXECHep7DXXuLkWVizQnEIsQRiTWZEiGQlh3Tq45RbX5dS2rVurYuJE2LnT6yiNCTtLEMacSHpC2LrVlfcoUwaGDHFXRvXu7epC2VmFiVKWIIwJRLFiGQlhzRq44QaYMwdatoT4eFdp1hY2MlHGEoQxOdW4sUsIW7e6tSkKFYJBgzIWNlq+3OsIjQkJSxDGBCs2Fm66CVascAsb9ejhBrebNctYx8IWNjL5mCUIY0IhKQmmTnVnFU8+6arI9ut3bGGj2O+/t7EKk+9YgjAmlEqXdlc9ff01fPIJdOkC06aR1L+/K0P+4IOwaZPXURoTEEsQxoSDCLRoAS+9BFu3smHwYChfHu67D2rXdq9Nngx//OF1pMZkyxKEMeFWpgzbOneGJUsgJQX+8x83NjFoEFSqBJdeCq++auMVJuJYgjAmL9WoAcOHuy6or7+GoUPh22/huuugYkXo2RPefdfWrDARwRKEMV5p1MidTaSkuLOLXr3g/fddxdnKld1Yhk3EMx6yBGGM1woUgPPPh2eegW3b4O23oX17mDbNTcSrVcuVJl+3zutIzSnGEoQxkaRwYbc+xcyZrorsiy/CWWe5M40GDSAxESZMcAUFjQkzSxDGRKqSJV15jw8+cPMrHn/cJZC77nLrVrRt6+Ze7NrldaQmSlmCMCY/qFgRbrsNvvgCvv8eRo92SeOmm+CMM+CKK+DNN2H/fq8jNVEkrAlCRDqKyAYR+VFERmTxek8R+dp3+1RE4v1eSxGRb0RktYhYcRtj0tWp41a/W7/elfi4+Wb4/HPo1s0lkr59YeFCW2fb5FrYEoSIxACTgUuA+kAPEamfabOfgAtUtTEwFpiS6fW2qpqgqknhitOYfEvElfiYONGNSXz4oVsd78034cIL3YJHQ4a4WlF2JZQJQjjPIJoDP6rqJlU9CMwELvffQFU/VdX0DtTPgaphjMeY6BUTAx06wPTpsH07zJoFzZu7ulBJSW5dizFjYONGryM1+YhomL5ZiEhXoKOq3uh73As4R1UHZbP9UKCe3/Y/AbsABZ5V1cxnF+n79QP6AVSsWLHpzJkzg4o3LS2N2NjYoPaNNNHSlmhpB3jXloJ79lB+yRIqLlzIaWvWALDn7LPZ3qEDv7dpw6EyZXJ8zGj5u0RLOyB3bWnbtu2KbHtpVDUsN6AbMNXvcS/giWy2bQt8B5T1e66y72cFYA3Q+mTv2bRpUw3W4sWLg9430kRLW6KlHaoR0paff1YdP141Pl4VVGNiVC++WPWll1T37An4MBHRlhCIlnao5q4twHLN5jM1nF1MW4Bqfo+rAlszbyQijYGpwOWquiP9eVXd6vv5OzAb12VljAlWtWowbBisXu3Kewwb5ga6e/d2g9vXXAPz5sHBg15HaiJEOBPEV0AdEYkTkcLANcBc/w1EpDrwP6CXqn7v93wJESmZfh+4CPg2jLEac2pp0AAeesiVHl+2DPr0cVc+de7sCggOHOieP3rU60iNh8KWIFT1MDAI+ADXfTRLVdeKyAARGeDb7H6gLPBUpstZKwLLRGQN8CXwrqq+H65YjTllFSjgynk89ZSbVzFvHlx0kZvBff75rszH3Xe7Mw5zyikYzoOr6nxgfqbnnvG7fyNwYxb7bQLiMz9vjAmjwoVdocBOnVzp8TlzXBnyRx5xpT4aN4Zrr6VoVbvY8FRhM6mNMf8UG+tKkL/3njuzeOIJKF4cRozg3Ouug4YN4Z573AQ964aKWpYgjDEnVqGCW9zos89g0yZ+uOUWN6j98MNw3nluzOLGG2HuXNi71+toTQhZgjDGBC4ujl+7doVFi9xyqTNmQLt28MYbcPnlULasG+ieOhV++83raE0uhXUMwhgTxU4/HXr0cLeDB92iR3Pnutu8eW6bc85xCaNzZ3fllIi3MZscsTMIY0zuFS7sSn1MmgQ//QRr1sDYsW584t573ep5Z54JgwfD4sW2pGo+YQnCGBNaIu6Kp5Ej4csv4ddf4dlnXT2op592XVIVKrj1t19/HXbv9jpikw1LEMaY8KpcGfr1g3fegR07YPZst37Fhx+62dvlyrnqs0884dbnNhHDEoQxJu+UKAFdurj1trdtg08+cSXJt2xxCyLFxUF8PNx3n1vrwi6h9ZQlCGOMN2JioEULGD8evvsONmxw622fdporA9K8OVStCv37w7vvwr59Xkd8yrEEYYyJDGedBXfeCR9/DL//Di+95MqAzJjhZneXK+e6pqZPd5fYmrCzy1yNMZGnbFno1cvdDhyA5OSMS2jnzHED4S1aZFxCW7euXUIbBnYGYYyJbEWKwMUXw+TJ8PPPsHKlW5N7714YPtxdHVW3Lgwd6uZiHD7sdcRRwxKEMSb/EIHERBg92iWKn392iaNWLTcH44ILXBmQ3r3d2typqV5HnK9ZgjDG5F/VqsHNN8P778Off7qSH5dd5ga1u3Vz4xYdO7py5r/84nW0+Y4lCGNMdChVCrp2dYPb27e7we5bb4WNG+GWW6B6dWjSBB54AFatAreksTkBSxDGmOhTsCC0bu0um/3+e3cZ7fjxrmT5Aw9Akyac2727q0L7xhuwa5fXEUckSxDGmOgmAvXquTW4ly1zVWanTye1Xj03TnH11a4r6rzzYNQo+PRTG+j2sQRhjDm1VKgAffqwdswYN26xbJmrG6XqCgy2bAnly7vuqueecwPhpyibB2GMOXUVLOgSQsuWrutp505YuBA++MDd3nrLbVevnrvU9uKL3ZVSxYt7G3cesQRhjDHpypRxXU5XX+3OKNatgwULXLJ49ll4/HFX2vz88zMSRqNGUTtJz7qYjDEmKyJukaPBg91ltDt3ukQxaJAbxxg2zBUWrFIF+vSB116LuhIgliCMMSYQxYrBRRfBf/8L337rKtBOm+aulpo3D6691k3SS0pyiyQtWZLvF0ayBGGMMcGoUgWuvx5mznTFBb/4wo1jFC3qLqm94AJXU6pLFzdRb+NGryPOMRuDMMaY3IqJceXJmzd3a1ns3g0ffZQx2P3222672rUzxi7atoWSJb2N+yQsQRhjTKiVLu1Kk19xhRvs/uGHjGTxwgvujKJQIVeRNj1hJCRAgcjq1ImsaIwxJtqIuLUubr3VLbu6c6c7uxgyxJ1p3HMPNG0KZ5zh1ul+6SU3CB4B7AzCGGPyUpEirnupbVv4z39cMvjwQ3c57YIFboEkcFdIXXyxGxhv1crtl8fsDMIYY7x0xhluYaSXX3brdK9cCf/+N5x+OkycCB06uPkZl13mSppv2JBnhQbtDMIYYyJFgQJuvYvERBgxAtLSYPHijMl68+e77WrUyDi7aN8+bOFYgjDGmEgVGwv/93/uBvDTTxmD3a+9BlOmQEwMCQ0awIoVrnRICFmCMMaY/CIuDgYMcLdDh+Dzz2HBAvauWsVpIU4OYAnCGGPyp0KFXE2o88/n++RkKofhLWyQ2hhjTJYsQRhjjMlSWBOEiHQUkQ0i8qOIjMji9Z4i8rXv9qmIxAe6rzHGmPAKW4IQkRhgMnAJUB/oISL1M232E3CBqjYGxgJTcrCvMcaYMArnGURz4EdV3aSqB4GZwOX+G6jqp6qavlr450DVQPc1xhgTXuG8iqkK8Ivf4y3AOSfY/gbgvZzuKyL9gH4AFStWJDk5Oahg09LSgt430kRLW6KlHWBtiUTR0g4IX1vCmSCyWoMvy/nhItIWlyBa5XRfVZ2Cr2sqKSlJ27Rpk+NAAZKTkwl230gTLW2JlnaAtSUSRUs7IHxtCWeC2AJU83tcFdiaeSMRaQxMBS5R1R052dcYY0z4iIap6JOIFAS+B9oDvwJfAdeq6lq/baoDHwG9VfXTnOybzXv+AWwOMuRywJ9B7htpoqUt0dIOsLZEomhpB+SuLTVUtXxWL4TtDEJVD4vIIOADIAaYpqprRWSA7/VngPuBssBTIgJwWFWTsts3gPfMspGBEJHlqpoU7P6RJFraEi3tAGtLJIqWdkD42hLWUhuqOh+Yn+m5Z/zu3wjcGOi+xhhj8o7NpDbGGJMlSxAZpngdQAhFS1uipR1gbYlE0dIOCFNbwjZIbYwxJn+zMwhjjDFZsgRhjDEmS6d8ghCRaSLyu4h863UsuSEi1URksYh8JyJrReR2r2MKlogUFZEvRWSNry0PeB1TbohIjIisEpF3vI4lN0QkRUS+EZHVIrLc63hyQ0ROE5E3RWS97//MeV7HFAwRqev7e6Tf9ojIHSE7/qk+BiEirYE04CVVbeh1PMESkUpAJVVdKSIlgRVAF1Vd53FoOSZuUkwJVU0TkULAMuB2Vf3c49CCIiJDgCSglKp28jqeYIlICpCkqvl+cpmIvAgsVdWpIlIYKK6qf3kdV274qmD/CpyjqsFOGD7OKX8GoapLgJ1ex5FbqrpNVVf67qcC3+GKHuY76qT5Hhby3fLlNxkRqQpchisnYyKAiJQCWgPPA6jqwfyeHHzaAxtDlRzAEkRUEpGaQCLwhbeRBM/XLbMa+B34UFXza1seA4YBR70OJAQUWCAiK3xVlPOrWsAfwHRf199UESnhdVAhcA3wWigPaAkiyohILPAWcIeq7vE6nmCp6hFVTcAVamwuIvmu+09EOgG/q+oKr2MJkZaq2gS3kNctvu7Z/Kgg0AR4WlUTgb+BfL1qpa+brDPwRiiPawkiivj6698CXlXV/3kdTyj4Tv2TgY4ehxKMlkBnX9/9TKCdiLzibUjBU9Wtvp+/A7NxC3vlR1uALX5npW/iEkZ+dgmwUlW3h/KgliCihG9g93ngO1V91Ot4ckNEyovIab77xYAOwHpvo8o5Vb1bVauqak3c6f9Hqnqdx2EFRURK+C5+wNcdcxGQL6/8U9XfgF9EpK7vqfZAvruYI5MehLh7CcJcrC8/EJHXgDZAORHZAoxS1ee9jSooLYFewDe+vnuAe3xFD/ObSsCLvqsyCgCzVDVfXyIaBSoCs31VlwsCM1T1fW9DypVbgVd9XTObgOs9jidoIlIcuBDoH/Jjn+qXuRpjjMmadTEZY4zJkiUIY4wxWbIEYYwxJkuWIIwxxmTJEoQxxpgsWYIw5iRE5Eimipkhm3UrIjXzeyVhE71O+XkQxgRgn6/shzGnFDuDMCZIvvURxvvWrvhSRM70PV9DRBaJyNe+n9V9z1cUkdm+dS7WiEgL36FiROQ539oXC3yzxxGR20Rkne84Mz1qpjmFWYIw5uSKZepi6u732h5VbQ48iavciu/+S6raGHgVmOR7fhLwsarG42r/rPU9XweYrKoNgL+Aq3zPjwASfccZEK7GGZMdm0ltzEmISJqqxmbxfArQTlU3+Qol/qaqZUXkT9ziTYd8z29T1XIi8gdQVVUP+B2jJq6ceR3f4+FAIVV9UETexy1mNQeY47dGhjF5ws4gjMkdzeZ+dttk5YDf/SNkjA1eBkwGmgIrRMTGDE2esgRhTO509/v5me/+p7jqrQA9cUumAiwCBsKxBZFKZXdQESkAVFPVxbgFh04D/nEWY0w42TcSY06umF+FXID3VTX9UtciIvIF7stWD99ztwHTROQu3Mpl6ZVCbwemiMgNuDOFgcC2bN4zBnhFREoDAkyMkmUxTT5iYxDGBMk3BpGkqn96HYsx4WBdTMYYY7JkZxDGGGOyZGcQxhhjsmQJwhhjTJYsQRhjjMmSJQhjjDFZsgRhjDEmS/8PZxjlPmKwv+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1000)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 학습시킨 ```word2vector```를 저장시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim)) # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀작성\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```gensim```을 사용해서 학습시킨 ```word2vector```를 사용해서 ```대박```이라는 단어와 연관성이 있는 단어들을 뽑아보았다.  \n",
    "영화리뷰라고 생각해보았을 때, 긍정적인 평가들이 나오는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['대박']\n",
    "# vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('슬퍼요', 0.5566833019256592),\n",
       " ('괜춘', 0.5530017614364624),\n",
       " ('최고', 0.5513213872909546),\n",
       " ('진진', 0.5508062839508057),\n",
       " ('먹먹', 0.544702410697937),\n",
       " ('습니당', 0.5446221828460693),\n",
       " ('즐겼', 0.5427483320236206),\n",
       " ('담백', 0.5413448214530945),\n",
       " ('여신', 0.5374443531036377),\n",
       " ('최상', 0.5369764566421509)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"대박\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능개선\n",
    "- [pre-trained word vectors](https://github.com/Kyubyong/wordvectors)\n",
    "    - 한국어를 다운로드\n",
    "    - 위키피디아를 통해서 만든 Word2Vec를 만든 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word2vec.txt',\n",
       " 'kowiki-20200820-pages-articles-multistream-index.txt.bz2',\n",
       " 'ratings_test.txt',\n",
       " 'GoogleNews-vectors-negative300.bin.gz',\n",
       " 'ko.tsv',\n",
       " 'ko.zip',\n",
       " 'kowiki-20200820-pages-articles-multistream.xml.bz2',\n",
       " 'wordvectors',\n",
       " 'ko.bin',\n",
       " 'ratings_train.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('sentiment_classification/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aiffel0042/aiffel/sentiment_classification/ko.tsv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " os.getenv('HOME')+'/aiffel/sentiment_classification/ko.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 코드는 다음과 같다.  \n",
    "```python\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "word2vec = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "```\n",
    "하지만 ```bin```파일로 저장되어 있는 ```word2vec```를 불러오기 위해서는 아래와 같이 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec.load(word2vec_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.12250227, -0.26166117,  0.1601894 ,  0.24988233, -0.19694664,\n",
       "        0.20742898,  0.23358916, -0.08032743,  0.07419734,  0.28976992,\n",
       "        0.05920417, -0.24217431,  0.42650384,  0.37083197,  0.01488842,\n",
       "       -0.15399031,  0.21594983,  0.16782928,  0.04716487, -0.3933347 ,\n",
       "        0.06105555, -0.13588727, -0.0257909 , -0.06074918,  0.04168789,\n",
       "        0.34588724,  0.24693313, -0.05122459,  0.16371667,  0.05747311,\n",
       "       -0.12627307, -0.16464052, -0.29741055,  0.17121391, -0.24180788,\n",
       "       -0.28056645, -0.06616814,  0.15681611,  0.20206362, -0.1660444 ,\n",
       "        0.00203782, -0.2563252 , -0.24074501, -0.63730514,  0.35244125,\n",
       "        0.05436644, -0.14913762, -0.06556495, -0.05610788,  0.11254067,\n",
       "       -0.09251513, -0.28059378,  0.07197419,  0.11595767,  0.15117767,\n",
       "       -0.00541334, -0.128903  ,  0.04034068, -0.22690742,  0.00775241,\n",
       "        0.16708778,  0.10937496, -0.17221814,  0.04758313,  0.321897  ,\n",
       "        0.0646909 ,  0.292136  , -0.07984147,  0.09785581,  0.181296  ,\n",
       "        0.17631158,  0.01031382, -0.43260768,  0.01173338,  0.03490037,\n",
       "       -0.0076601 , -0.06428192, -0.2924691 ,  0.24474835,  0.07950445,\n",
       "       -0.09601387, -0.34834263, -0.17978796,  0.23437631, -0.15391289,\n",
       "        0.01297345, -0.04877474, -0.22579618, -0.06827989, -0.266499  ,\n",
       "       -0.18218975, -0.45568773, -0.19330987,  0.09304521,  0.08007847,\n",
       "       -0.08579313, -0.01735996, -0.20058121, -0.11037695, -0.04257905,\n",
       "       -0.01491661,  0.24702635, -0.06080532,  0.07469252,  0.02070692,\n",
       "        0.20998064, -0.12500262, -0.16058917,  0.13576448, -0.01957137,\n",
       "       -0.03530353,  0.02538178,  0.02707971,  0.02211284,  0.4662458 ,\n",
       "       -0.13323712, -0.31756285, -0.26687905, -0.2932379 ,  0.16787444,\n",
       "       -0.00277177,  0.11576287, -0.0071318 ,  0.04130382, -0.0535576 ,\n",
       "        0.5331611 ,  0.15177174,  0.308193  ,  0.12067769, -0.11636538,\n",
       "       -0.16276449, -0.1450912 , -0.07153927,  0.00982432,  0.16283946,\n",
       "        0.16073047, -0.30461156,  0.06590325,  0.18986021,  0.22578666,\n",
       "       -0.10132927,  0.1319676 , -0.28178945,  0.03667555, -0.02295887,\n",
       "       -0.15407115, -0.3441792 , -0.1218596 , -0.3528504 , -0.14319238,\n",
       "       -0.3211591 ,  0.14814556, -0.10278759,  0.23421551,  0.08331902,\n",
       "        0.00759588,  0.39796677, -0.13322656, -0.33425966, -0.2488725 ,\n",
       "        0.22625662, -0.01530029, -0.1754215 ,  0.06301978, -0.09565204,\n",
       "        0.22803056, -0.09959741, -0.08168349,  0.02098079,  0.09322228,\n",
       "       -0.00068385, -0.18893392,  0.2519263 ,  0.05090755,  0.2681667 ,\n",
       "        0.34096426, -0.18010454,  0.16246942,  0.01820518, -0.0705201 ,\n",
       "        0.08623672, -0.01494653, -0.21275468, -0.0316746 ,  0.26614192,\n",
       "        0.02781401,  0.1385179 ,  0.38353992, -0.08111849,  0.10542663,\n",
       "       -0.19549905,  0.01497585,  0.05798322,  0.02531051, -0.04150281,\n",
       "       -0.12611519, -0.05583593, -0.07526224, -0.08963452,  0.0068798 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = word2vec['대박']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 불러온 ```word2vec```를 사용해서 ```embedding_matrix```를 생성해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  \n",
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 만든 임베딩을 여기서 학습하는데 활용한다.  \n",
    "모델은 위에서 사용한것과 동일하게 ```LSTM```을 사용하였고 ```LSTM``` 레이어의 차원도 ```128```로 설정하였다.  \n",
    "여기서 ```Embedding``` 레이어에 ```embedding_matrix```로 초기화를 해주었기 때문에 ```word_vector_dim```과 같은 경우는 기존에 초기화 되어있는 임베딩의 차원인 200으로 줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               467968    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 2056      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,470,033\n",
      "Trainable params: 2,470,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix), \n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "\n",
    "model.add(keras.layers.LSTM(256))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.5027 - accuracy: 0.7323\n",
      "Epoch 00001: val_accuracy did not improve from 0.86890\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.5025 - accuracy: 0.7324 - val_loss: 0.3663 - val_accuracy: 0.8371\n",
      "Epoch 2/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.8577\n",
      "Epoch 00002: val_accuracy did not improve from 0.86890\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.3298 - accuracy: 0.8578 - val_loss: 0.3249 - val_accuracy: 0.8609\n",
      "Epoch 3/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.8815\n",
      "Epoch 00003: val_accuracy did not improve from 0.86890\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.2834 - accuracy: 0.8815 - val_loss: 0.3204 - val_accuracy: 0.8655\n",
      "Epoch 4/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.8954\n",
      "Epoch 00004: val_accuracy did not improve from 0.86890\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.2500 - accuracy: 0.8954 - val_loss: 0.3239 - val_accuracy: 0.8653\n",
      "Epoch 5/20\n",
      "986/986 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.9104\n",
      "Epoch 00005: val_accuracy improved from 0.86890 to 0.87000, saving model to model.h5\n",
      "986/986 [==============================] - 20s 20ms/step - loss: 0.2193 - accuracy: 0.9104 - val_loss: 0.3151 - val_accuracy: 0.8700\n",
      "Epoch 6/20\n",
      "985/986 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9233\n",
      "Epoch 00006: val_accuracy did not improve from 0.87000\n",
      "986/986 [==============================] - 19s 19ms/step - loss: 0.1894 - accuracy: 0.9233 - val_loss: 0.3553 - val_accuracy: 0.8662\n",
      "Epoch 7/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.1609 - accuracy: 0.9364\n",
      "Epoch 00007: val_accuracy did not improve from 0.87000\n",
      "986/986 [==============================] - 19s 19ms/step - loss: 0.1609 - accuracy: 0.9364 - val_loss: 0.3627 - val_accuracy: 0.8664\n",
      "Epoch 8/20\n",
      "984/986 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9470\n",
      "Epoch 00008: val_accuracy did not improve from 0.87000\n",
      "986/986 [==============================] - 18s 19ms/step - loss: 0.1355 - accuracy: 0.9470 - val_loss: 0.4062 - val_accuracy: 0.8666\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20\n",
    "\n",
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1,\n",
    "                   callbacks=[early_stopping, model_check])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 3s - loss: 0.4221 - accuracy: 0.8628\n",
      "[0.4220728278160095, 0.8628069162368774]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(X_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오!!!!! 놀랍게도 ```validation accuracy```가 **```0.002```** 증가했다.  \n",
    "그래프로 시각화도 해보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "# 시각화를 시도한다.\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# 빨간 실선으로 표시\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# 파란 실선으로 표시\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 세가지의 모델을 사용해보았다.\n",
    "    1. ```1D CNN``` : ```0.8413```\n",
    "    2. ```LSTM``` : ```0.8424```\n",
    "    3. ```GlobalMaxPooling1D``` : ```0.8402```\n",
    "- 그 중에서 제일 좋은 LSTM으로 선택, 모델구조 찾기\n",
    "    - 하이퍼파라미터를 튜닝하기 전에 모델구조에 대해서 생각해 보았다.\n",
    "        1. CNN 1D -> LSTM\n",
    "        2. LSTM -> LSTM\n",
    "        3. LSTM 단일 레이어\n",
    "    - 하지만 CNN을 추가한 경우 생각보다 점수가 낮게 나오고 LSTM 레이어를 두개를 사용해도 성능은 나아지지 않았다.\n",
    "- 하이퍼파라미터 설정\n",
    "    - ```word_vector_dim = 1000```\n",
    "    - LSTM 레이어의 차원 수 = ```128```, ```dropout = 0.7``` 적용\n",
    "    - ```Adam``` optimizer의 ```learning rate = 0.0005```\n",
    "    - ```batch_size = 128```\n",
    "- Callback 함수 사용\n",
    "    - ```EearlyStopping```\n",
    "    - ```Checkpoint```\n",
    "- 정확도는 ```0.8413``` -> ```0.86``` 으로 약 2퍼센트 성능 향상\n",
    "---\n",
    "\n",
    "- 학습한 임베딩 결과 확인\n",
    "    - '대박'이라는 단어를 통해서 유사단어를 찾아 보았다.\n",
    "    - 대부분 영화리뷰로써 긍정적인 평가를 한 결과가 나왔다.\n",
    "![image](https://user-images.githubusercontent.com/48716219/91934045-42e38000-ed25-11ea-8d21-6725bd6cd550.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- 사전 학습된 워드임베딩적용 후 같은 파라미터로 학습\n",
    "    - 정확도 ```0.86``` -> ```0.862``` 로 약 0.2퍼센트 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
